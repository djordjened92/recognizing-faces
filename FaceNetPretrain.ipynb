{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0b70c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.data import Dataset\n",
    "from tensorflow import keras\n",
    "\n",
    "from datetime import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "from tensorflow.keras.optimizers import RMSprop, SGD, Adam\n",
    "from tensorflow.keras.applications import MobileNet, ResNet50, InceptionV3\n",
    "from tensorflow.keras.applications.mobilenet import preprocess_input as mobilenet_preprocess\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input as resnet_preprocess\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input as inception_preprocess\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import Callback, LearningRateScheduler\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout, Lambda, Conv1D, Attention, GlobalAveragePooling1D, BatchNormalization, Layer\n",
    "from keras_facenet import FaceNet\n",
    "\n",
    "random.seed(123)\n",
    "tf.random.set_seed(12)\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99f6811",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/train_img_embeddings.pkl', 'rb') as f:\n",
    "       train_embeddings = pickle.load(f)\n",
    "print(f'The keys examples: {list(train_embeddings.keys())[:5]}')\n",
    "\n",
    "embedding_shape = list(list(train_embeddings.values())[0].values())[0].shape\n",
    "print(f'Embeddings shape: {embedding_shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c039106",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "for k, v in train_embeddings.items():\n",
    "    cnt += len(v)\n",
    "\n",
    "print(f'Total imgs: {cnt}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4093249a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (224, 224, 3)\n",
    "train_path = './data/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f2ca36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mobilenet(input_shape, l2_value, dropout):\n",
    "    mobile = MobileNet(\n",
    "        input_shape=input_shape,\n",
    "        dropout=dropout,\n",
    "        include_top=False,\n",
    "        pooling='avg',\n",
    "        alpha=1.,\n",
    "        weights='imagenet'\n",
    "    )\n",
    "    \n",
    "    for layer in mobile.layers:\n",
    "        layer.trainable = True\n",
    "        if hasattr(layer, 'kernel_regularizer'):\n",
    "            setattr(layer, 'kernel_regularizer', keras.regularizers.l2(l2_value))\n",
    "        \n",
    "    x = Dense(512, kernel_regularizer=l2(l2_value), activation='relu')(mobile.output)\n",
    "    x = Lambda(lambda x: K.l2_normalize(x,axis=1))(x)\n",
    "    return Model(mobile.input, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c185fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batching(embeddings, batch_size, input_shape, preprocess):\n",
    "    cnt = 0\n",
    "    imgs = []\n",
    "    labels = []\n",
    "    for person, embs in embeddings.items():\n",
    "        person_path = os.path.join(train_path, person)\n",
    "        \n",
    "        for img_name, emb in embs.items():\n",
    "            img_path = os.path.join(person_path, img_name)\n",
    "            img = image.load_img(img_path, target_size=(input_shape[0], input_shape[1]))\n",
    "            img = np.array(img).astype('float32')\n",
    "            imgs.append(img)\n",
    "            labels.append(emb)\n",
    "            if len(labels) == batch_size:\n",
    "                yield (preprocess(np.array(imgs)), np.array(labels).astype(float))\n",
    "                imgs, labels = [], []\n",
    "\n",
    "def repeat_generator(embeddings, batch_size, input_shape, preprocess):\n",
    "    while True:\n",
    "        for e in batching(embeddings, batch_size, input_shape, preprocess):\n",
    "            yield e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a174fedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training-Validation split\n",
    "VAL_FACTOR = 0.12\n",
    "keys = list(train_embeddings.keys())\n",
    "random.shuffle(keys)\n",
    "keys_length = len(keys)\n",
    "val_factor = int(keys_length * VAL_FACTOR)\n",
    "val_keys = keys[:val_factor]\n",
    "train_keys = keys[val_factor:]\n",
    "print(f'Total keys: {keys_length}, train keys: {len(train_keys)}, valid keys: {len(val_keys)}')\n",
    "\n",
    "val_embs = {k:train_embeddings[k] for k in val_keys}\n",
    "train_embs = {k:train_embeddings[k] for k in train_keys}\n",
    "\n",
    "train_len = 0\n",
    "for k, v in train_embs.items():\n",
    "    train_len +=len(v.keys())\n",
    "\n",
    "val_len = 0\n",
    "for k, v in val_embs.items():\n",
    "    val_len +=len(v.keys())\n",
    "\n",
    "print(f'Total - train imgs: {train_len}, valid imgs: {val_len}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae24ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 7e-5\n",
    "l2_value = 1e-5\n",
    "dropout = 0.25\n",
    "optimizer = 'Adam'\n",
    "batch_size = 12\n",
    "epochs = 1000\n",
    "\n",
    "model = mobilenet(input_shape, l2_value, dropout)\n",
    "optimizer = eval(optimizer)(learning_rate=lr)\n",
    "model.compile(loss='cosine_similarity', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e2694c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'model_002_mobile_512'\n",
    "ckpt_dir = os.path.join('pretrained/checkpoints', model_name)\n",
    "log_dir = os.path.join('pretrained/logs', model_name)\n",
    "\n",
    "if not os.path.exists(ckpt_dir):\n",
    "    os.makedirs(ckpt_dir)\n",
    "\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "ckpt_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=os.path.join(ckpt_dir, 'weights.{epoch:02d}.hdf5'),\n",
    "    save_weights_only=True,\n",
    "    period=3\n",
    ")\n",
    "tb_callback = keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "\n",
    "model.fit(\n",
    "    repeat_generator(train_embs, batch_size, input_shape, mobilenet_preprocess),\n",
    "    epochs=epochs,\n",
    "    steps_per_epoch=train_len // batch_size,\n",
    "    validation_data=repeat_generator(val_embs, batch_size, input_shape, mobilenet_preprocess),\n",
    "    validation_steps=val_len // batch_size,\n",
    "    callbacks=[ckpt_callback, tb_callback]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
