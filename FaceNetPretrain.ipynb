{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51df33e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-16 12:56:52.797701: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.data import Dataset\n",
    "from tensorflow import keras\n",
    "\n",
    "from datetime import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "from tensorflow.keras.optimizers import RMSprop, SGD, Adam\n",
    "from tensorflow.keras.applications import MobileNet, ResNet50, InceptionV3\n",
    "from tensorflow.keras.applications.mobilenet import preprocess_input as mobilenet_preprocess\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input as resnet_preprocess\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input as inception_preprocess\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import Callback, LearningRateScheduler\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout, Lambda, Conv1D, Attention, GlobalAveragePooling1D, BatchNormalization, Layer\n",
    "from keras_facenet import FaceNet\n",
    "\n",
    "random.seed(123)\n",
    "tf.random.set_seed(12)\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22a2ba75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The keys examples: ['F0475/MID3', 'F0475/MID7', 'F0475/MID6', 'F0475/MID4', 'F0475/MID2']\n",
      "Embeddings shape: (512,)\n"
     ]
    }
   ],
   "source": [
    "with open('data/train_img_embeddings.pkl', 'rb') as f:\n",
    "       train_embeddings = pickle.load(f)\n",
    "print(f'The keys examples: {list(train_embeddings.keys())[:5]}')\n",
    "\n",
    "embedding_shape = list(list(train_embeddings.values())[0].values())[0].shape\n",
    "print(f'Embeddings shape: {embedding_shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "885217ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total imgs: 20080\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for k, v in train_embeddings.items():\n",
    "    cnt += len(v)\n",
    "\n",
    "print(f'Total imgs: {cnt}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50e59655",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (224, 224, 3)\n",
    "train_path = './data/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2154198",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mobilenet(input_shape, l2_value, dropout):\n",
    "    mobile = MobileNet(\n",
    "        input_shape=input_shape,\n",
    "        dropout=dropout,\n",
    "        include_top=False,\n",
    "        pooling='avg',\n",
    "        alpha=.75,\n",
    "        weights='imagenet'\n",
    "    )\n",
    "    \n",
    "    for layer in mobile.layers:\n",
    "        layer.trainable = True\n",
    "        if hasattr(layer, 'kernel_regularizer'):\n",
    "            setattr(layer, 'kernel_regularizer', keras.regularizers.l2(l2_value))\n",
    "        \n",
    "    x = Dense(512, kernel_regularizer=l2(l2_value), activation='relu')(mobile.output)\n",
    "    x = Lambda(lambda x: K.l2_normalize(x,axis=1))(x)\n",
    "    return Model(mobile.input, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3571345",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batching(embeddings, batch_size, input_shape, preprocess):\n",
    "    cnt = 0\n",
    "    imgs = []\n",
    "    labels = []\n",
    "    for person, embs in embeddings.items():\n",
    "        person_path = os.path.join(train_path, person)\n",
    "        \n",
    "        for img_name, emb in embs.items():\n",
    "            img_path = os.path.join(person_path, img_name)\n",
    "            img = image.load_img(img_path, target_size=(input_shape[0], input_shape[1]))\n",
    "            img = np.array(img).astype('float32')\n",
    "            imgs.append(img)\n",
    "            labels.append(emb)\n",
    "            if len(labels) == batch_size:\n",
    "                yield (preprocess(np.array(imgs)), np.array(labels).astype(float))\n",
    "                imgs, labels = [], []\n",
    "\n",
    "def repeat_generator(embeddings, batch_size, input_shape, preprocess):\n",
    "    while True:\n",
    "        for e in batching(embeddings, batch_size, input_shape, preprocess):\n",
    "            yield e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "298a17aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total keys: 3965, train keys: 3490, valid keys: 475\n",
      "Total - train imgs: 17516, valid imgs: 2564\n"
     ]
    }
   ],
   "source": [
    "# Training-Validation split\n",
    "VAL_FACTOR = 0.12\n",
    "keys = list(train_embeddings.keys())\n",
    "random.shuffle(keys)\n",
    "keys_length = len(keys)\n",
    "val_factor = int(keys_length * VAL_FACTOR)\n",
    "val_keys = keys[:val_factor]\n",
    "train_keys = keys[val_factor:]\n",
    "print(f'Total keys: {keys_length}, train keys: {len(train_keys)}, valid keys: {len(val_keys)}')\n",
    "\n",
    "val_embs = {k:train_embeddings[k] for k in val_keys}\n",
    "train_embs = {k:train_embeddings[k] for k in train_keys}\n",
    "\n",
    "train_len = 0\n",
    "for k, v in train_embs.items():\n",
    "    train_len +=len(v.keys())\n",
    "\n",
    "val_len = 0\n",
    "for k, v in val_embs.items():\n",
    "    val_len +=len(v.keys())\n",
    "\n",
    "print(f'Total - train imgs: {train_len}, valid imgs: {val_len}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8da763f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-16 12:56:55.338480: W tensorflow/stream_executor/platform/default/dso_loader.cc:65] Could not load dynamic library 'libcuda.so.1'; dlerror: /lib/x86_64-linux-gnu/libcuda.so.1: file too short; LD_LIBRARY_PATH: /usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2021-09-16 12:56:55.338529: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-09-16 12:56:55.338569: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:163] no NVIDIA GPU device is present: /dev/nvidia0 does not exist\n",
      "2021-09-16 12:56:55.339285: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 16. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-3\n",
    "l2_value = 1e-5\n",
    "dropout = 0.1\n",
    "optimizer = 'Adam'\n",
    "batch_size = 16\n",
    "epochs = 1000\n",
    "\n",
    "model = mobilenet(input_shape, l2_value, dropout)\n",
    "optimizer = eval(optimizer)(learning_rate=lr)\n",
    "model.compile(loss='mean_squared_error', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd307957",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-16 12:56:57.577622: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-09-16 12:56:57.596817: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 3600000000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      " 189/1094 [====>.........................] - ETA: 9:20 - loss: 0.0053"
     ]
    }
   ],
   "source": [
    "train_generator = repeat_generator(train_embs, batch_size, input_shape, mobilenet_preprocess)\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    steps_per_epoch=train_len // batch_size,\n",
    "    validation_data=batching(val_embs, batch_size, input_shape, mobilenet_preprocess),\n",
    "    validation_steps=val_len // batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946e2ee6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
