{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-24 23:19:16.461959: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.data import Dataset\n",
    "from tensorflow import keras\n",
    "from keras_vggface.vggface import VGGFace\n",
    "\n",
    "from datetime import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, roc_auc_score\n",
    "from tensorflow.keras.optimizers import RMSprop, SGD, Adam\n",
    "from tensorflow.keras.applications import MobileNet, ResNet50, InceptionV3\n",
    "from tensorflow.keras.applications.mobilenet import preprocess_input as mobilenet_preprocess\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input as resnet_preprocess\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input as inception_preprocess\n",
    "from keras_vggface.utils import preprocess_input as vggface_preprocess\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import Callback, LearningRateScheduler, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout, Lambda, Conv1D, Attention, GlobalAveragePooling1D, BatchNormalization, Layer\n",
    "from keras_facenet import FaceNet\n",
    "\n",
    "random.seed(123)\n",
    "tf.random.set_seed(12)\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-24 23:19:19.225728: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcuda.so.1\n",
      "2021-09-24 23:19:19.287113: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-24 23:19:19.287460: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1734] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2070 SUPER computeCapability: 7.5\n",
      "coreClock: 1.815GHz coreCount: 40 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s\n",
      "2021-09-24 23:19:19.287486: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-24 23:19:19.316450: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcublas.so.11\n",
      "2021-09-24 23:19:19.316523: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-09-24 23:19:19.332868: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcufft.so.10\n",
      "2021-09-24 23:19:19.337607: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcurand.so.10\n",
      "2021-09-24 23:19:19.381372: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcutensor.so.1\n",
      "2021-09-24 23:19:19.387020: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcusolver.so.11\n",
      "2021-09-24 23:19:19.403195: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-09-24 23:19:19.404529: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-09-24 23:19:19.404900: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-24 23:19:19.406255: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-24 23:19:19.407838: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1872] Adding visible gpu devices: 0\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (224, 224, 3)\n",
    "train_path = './data/train'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training pairs generating\n",
    "\n",
    "Available training pairs from csv files are splitted to train - validation sets. Those pairs are positive(there is blood relation). For each set(train/valid) we additionally generate negative pairs.\n",
    "\n",
    "Positive pairs are generated according to the input csv file. For each person of positive pair we create one negative pair.\n",
    "In total we'll have twice more negative than positive pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_image_pair(pair, input_shape, shuffle=True, slice_imgs=1):\n",
    "    '''\n",
    "    Create pair of embeddings.\n",
    "    \n",
    "    Arguments:\n",
    "    p1, p2 -- paths to persons' images directories (familyID/personID)\n",
    "    \n",
    "    Returns:\n",
    "    pairs -- array of image pairs, pairing is alligned to smaller number of images\n",
    "    ''' \n",
    "    p1, p2 = [os.path.join(train_path, p) for p in pair]\n",
    "    \n",
    "    p1_imgs = os.listdir(p1)\n",
    "    p2_imgs = os.listdir(p2)\n",
    "    \n",
    "    if shuffle:\n",
    "        random.shuffle(p1_imgs)\n",
    "        random.shuffle(p2_imgs)\n",
    "    \n",
    "    p1_imgs = p1_imgs[:slice_imgs]\n",
    "    p2_imgs = p2_imgs[:slice_imgs]\n",
    "    \n",
    "    for i in range(len(p1_imgs)):\n",
    "        for j in range(len(p2_imgs)):\n",
    "            img1_path = os.path.join(p1, p1_imgs[i])\n",
    "            img2_path = os.path.join(p2, p2_imgs[j])\n",
    "            img1 = image.load_img(img1_path, target_size=(input_shape[0], input_shape[1]))\n",
    "            img2 = image.load_img(img2_path, target_size=(input_shape[0], input_shape[1]))\n",
    "            img1 = np.array(img1).astype('float32')\n",
    "            img2 = np.array(img2).astype('float32')\n",
    "            \n",
    "            yield img1, img2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairs_set(input_pairs, input_shape, shuffle=True, slice_imgs=1):\n",
    "    for pair, label in input_pairs:\n",
    "        try:\n",
    "            emb_pairs = make_image_pair(pair, input_shape, shuffle, slice_imgs)\n",
    "            for emb_pair in emb_pairs:\n",
    "                yield emb_pair, label\n",
    "        except (KeyError, FileNotFoundError):\n",
    "            continue\n",
    "\n",
    "def batched_pairs(input_pairs, batch_size, dataset_period, input_shape, preprocess, shuffle=True, slice_imgs=1):\n",
    "    imgs1 = []\n",
    "    imgs2 = []\n",
    "    labels = []\n",
    "    counter = 0\n",
    "    for example in pairs_set(input_pairs, input_shape, shuffle, slice_imgs):\n",
    "        # Get every nth sample\n",
    "        counter += 1\n",
    "        if counter % dataset_period:\n",
    "            continue\n",
    "        \n",
    "        exmpls, label = example\n",
    "        exmpl1, exmpl2 = exmpls\n",
    "        imgs1.append(exmpl1)\n",
    "        imgs2.append(exmpl2)\n",
    "        labels.append(label)\n",
    "        if len(labels) == batch_size:\n",
    "            yield {'input_1':preprocess(np.array(imgs1)), 'input_2':preprocess(np.array(imgs2))}, np.array(labels).astype(float)\n",
    "            imgs1, imgs2, labels = [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_val_set.json', 'r') as f:\n",
    "    train_val_set = json.load(f)\n",
    "\n",
    "train_rlt_list, neg_train_rltshps, valid_rlt_list, neg_valid_rltshps = list(train_val_set.values())\n",
    "train_rlt_list = train_rlt_list * 4\n",
    "\n",
    "train_rlts = list(zip(train_rlt_list + neg_train_rltshps, [True]*len(train_rlt_list) + [False]*len(neg_train_rltshps)))\n",
    "val_rlts = list(zip(valid_rlt_list + neg_valid_rltshps, [True]*len(valid_rlt_list) + [False]*len(neg_valid_rltshps)))\n",
    "\n",
    "random.shuffle(train_rlts)\n",
    "random.shuffle(val_rlts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Siamese network\n",
    "\n",
    "Initial experimenting is done with conv1D deep neural network, as additional option for experimenting there is simple attention module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mobilenet(input_shape, l2_value, dropout):\n",
    "    mobile = MobileNet(\n",
    "        input_shape=input_shape,\n",
    "        dropout=dropout,\n",
    "        include_top=False,\n",
    "        pooling='avg',\n",
    "        alpha=1.,\n",
    "        weights='imagenet'\n",
    "    )\n",
    "    \n",
    "    for layer in mobile.layers:\n",
    "        layer.trainable = True\n",
    "        if hasattr(layer, 'kernel_regularizer'):\n",
    "            setattr(layer, 'kernel_regularizer', keras.regularizers.l2(l2_value))\n",
    "        \n",
    "    x = Dense(512, kernel_regularizer=l2(l2_value), activation='relu')(mobile.output)\n",
    "    x = Lambda(lambda x: K.l2_normalize(x,axis=1))(x)\n",
    "    return Model(mobile.input, x)\n",
    "\n",
    "def inception(input_shape, l2_value, dropout):\n",
    "    inception = InceptionV3(\n",
    "        input_shape=input_shape,\n",
    "        include_top=False,\n",
    "        pooling='avg',\n",
    "        weights='imagenet'\n",
    "    )\n",
    "    \n",
    "    for layer in inception.layers:\n",
    "        layer.trainable = True\n",
    "        if hasattr(layer, 'kernel_regularizer'):\n",
    "            setattr(layer, 'kernel_regularizer', keras.regularizers.l2(l2_value))\n",
    "        \n",
    "    x = Dense(128, kernel_regularizer=l2(l2_value), activation='relu')(inception.output)\n",
    "    x = Lambda(lambda x: K.l2_normalize(x,axis=1))(x)\n",
    "    return Model(inception.input, x)\n",
    "\n",
    "def resnet50(input_shape, l2_value, dropout):\n",
    "    resnet = ResNet50(\n",
    "        input_shape=input_shape,\n",
    "        include_top=False,\n",
    "        pooling='avg',\n",
    "        weights='imagenet'\n",
    "    )\n",
    "    \n",
    "    for layer in resnet.layers:\n",
    "        layer.trainable = True\n",
    "        if hasattr(layer, 'kernel_regularizer'):\n",
    "            setattr(layer, 'kernel_regularizer', keras.regularizers.l2(l2_value))\n",
    "        \n",
    "    x = Dense(32, kernel_regularizer=l2(l2_value), activation='relu')(resnet.output)\n",
    "    x = Lambda(lambda x: K.l2_normalize(x,axis=1))(x)\n",
    "    return Model(resnet.input, x)\n",
    "\n",
    "def vggface_resnet50(input_shape, l2_value, dropout):\n",
    "    vggface_res = VGGFace(model='resnet50', include_top=False, input_shape=input_shape)\n",
    "    \n",
    "    for layer in vggface_res.layers:\n",
    "        layer.trainable = True\n",
    "        if hasattr(layer, 'kernel_regularizer'):\n",
    "            setattr(layer, 'kernel_regularizer', keras.regularizers.l2(l2_value))\n",
    "    \n",
    "    last_layer = vggface_res.get_layer('avg_pool').output\n",
    "    x = Flatten(name='flatten')(last_layer)\n",
    "    x = Lambda(lambda x: K.l2_normalize(x,axis=1))(x)\n",
    "    return Model(vggface_res.input, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss and metrics functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MARGIN = 0.28\n",
    "\n",
    "# Margins for positive and negative pairs in the batch\n",
    "margin_pos = 0.8 * MARGIN\n",
    "margin_neg = 1.2 * MARGIN\n",
    "\n",
    "def euclidean_distance(vectors):\n",
    "    x, y = vectors\n",
    "    sum_square = K.sum(K.square(x - y), axis=1)\n",
    "    return K.sqrt(K.maximum(sum_square, K.epsilon()))\n",
    "\n",
    "def cosine_distance(vectors):\n",
    "    x, y = vectors\n",
    "    x_norm = tf.norm(x, axis=1)\n",
    "    y_norm = tf.norm(y, axis=1)\n",
    "    x_y_dot = tf.einsum('ij,ij->i', x, y)\n",
    "    cos_sim = x_y_dot / (x_norm * y_norm + K.epsilon())\n",
    "    return 1. - cos_sim\n",
    "\n",
    "def cos_euc_dist(vectors):\n",
    "    euc = euclidean_distance(vectors)\n",
    "    cos_dist = cosine_distance(vectors)\n",
    "    return (1. - cos_dist) * euc\n",
    "\n",
    "def eucl_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)\n",
    "\n",
    "def contrastive_loss(y_true, y_pred):\n",
    "    weight_pos = 1.4\n",
    "    weight_neg = 1.\n",
    "    \n",
    "    pos_pred = y_true * y_pred\n",
    "    pos_neg = (1 - y_true) * y_pred\n",
    "    \n",
    "    pred_pos_m = K.mean(pos_pred, axis=0)\n",
    "    pred_neg_m = K.mean(pos_neg, axis=0)\n",
    "    \n",
    "    variance_loss = 0.5 * (K.mean(K.square(pred_pos_m - pos_pred)) + K.mean(K.square(pred_neg_m - pos_neg)))\n",
    "    \n",
    "    square_pred = K.square(K.maximum(y_pred - margin_pos, 0))\n",
    "    square_neg = K.square(K.maximum(margin_neg - y_pred, 0))\n",
    "    \n",
    "    return K.mean(y_true * weight_pos * square_pred + (1 - y_true) * weight_neg * square_neg) + 0.1 * variance_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 8e-7\n",
    "l2_value = 1e-9\n",
    "dropout = 0.\n",
    "epochs = 1000\n",
    "batch_size = 24\n",
    "eval_batch_size = 128\n",
    "dataset_period = 1\n",
    "eval_dataset_period = 1\n",
    "model_type = 'vggface_resnet50'\n",
    "preprocess = vggface_preprocess\n",
    "# 'euclidian' or 'cosine_distance'\n",
    "distance_type = 'cosine_distance'\n",
    "optimizer = 'Adam'\n",
    "\n",
    "# Learning rate scheduler\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch == 10:\n",
    "        return 0.5 * lr\n",
    "    elif epoch == 180:\n",
    "        return 0.8 * lr\n",
    "    elif epoch == 250:\n",
    "        return 0.5 * lr\n",
    "    elif epoch == 300:\n",
    "        return 0.7 * lr\n",
    "    elif epoch == 400:\n",
    "        return 0.3 *lr\n",
    "    elif epoch == 700:\n",
    "        return 0.6 *lr\n",
    "    return lr\n",
    "    \n",
    "lr_callback = LearningRateScheduler(scheduler)\n",
    "\n",
    "# Create dictionary of parameters for saving configuration\n",
    "train_config = {}\n",
    "for name in [\n",
    "    'learning_rate',\n",
    "    'l2_value',\n",
    "    'dropout',\n",
    "    'epochs',\n",
    "    'batch_size',\n",
    "    'model_type',\n",
    "    'dataset_period',\n",
    "    'eval_dataset_period',\n",
    "    'distance_type',\n",
    "    'optimizer',\n",
    "    'MARGIN'\n",
    "]:\n",
    "    train_config[name] = eval(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-24 23:19:19.579357: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-24 23:19:19.579635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1734] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2070 SUPER computeCapability: 7.5\n",
      "coreClock: 1.815GHz coreCount: 40 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s\n",
      "2021-09-24 23:19:19.579735: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-24 23:19:19.579984: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-24 23:19:19.580196: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1872] Adding visible gpu devices: 0\n",
      "2021-09-24 23:19:19.580660: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-24 23:19:21.371906: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-09-24 23:19:21.371941: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2021-09-24 23:19:21.371989: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2021-09-24 23:19:21.372200: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-24 23:19:21.372691: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-24 23:19:21.373141: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-24 23:19:21.373545: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6178 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2070 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5)\n",
      "2021-09-24 23:19:21.374921: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 16. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "data_augmentation = keras.Sequential([\n",
    "    keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
    "    keras.layers.experimental.preprocessing.RandomTranslation(height_factor=0.2, width_factor=0.2),\n",
    "    keras.layers.experimental.preprocessing.RandomContrast(factor=0.2),\n",
    "    keras.layers.experimental.preprocessing.RandomZoom(height_factor=0.2)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23561152"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_network = eval(model_type)(input_shape, l2_value, dropout)\n",
    "# base_network.load_weights('pretrained/checkpoints/model_001_mobile_512/weights.609.hdf5')\n",
    "base_network.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n",
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n",
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    }
   ],
   "source": [
    "# Creation of Siamese network\n",
    "input1 = Input(shape=input_shape, name='input_1')\n",
    "input2 = Input(shape=input_shape, name='input_2')\n",
    "\n",
    "processed1 = base_network(data_augmentation(input1))\n",
    "processed2 = base_network(data_augmentation(input2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential (Sequential)         (None, 224, 224, 3)  0           input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model (Functional)              (None, 2048)         23561152    sequential[0][0]                 \n",
      "                                                                 sequential[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None,)              0           model[0][0]                      \n",
      "                                                                 model[1][0]                      \n",
      "==================================================================================================\n",
      "Total params: 23,561,152\n",
      "Trainable params: 23,508,032\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dist_function = eval(distance_type)\n",
    "distance = Lambda(dist_function,\n",
    "                  output_shape=eucl_dist_output_shape)([processed1, processed2])\n",
    "\n",
    "model = Model([input1, input2], distance)\n",
    "optimizer = eval(optimizer)(learning_rate=learning_rate)\n",
    "model.compile(loss=contrastive_loss, optimizer=optimizer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run tensorboard plugin in order to track changes of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 7007 (pid 773877), started 3 days, 2:04:05 ago. (Use '!kill 773877' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-398a4f34095f9a9e\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-398a4f34095f9a9e\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 7007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=./logs --port=7007"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set length: 19429\n",
      "Valid set length: 8084\n"
     ]
    }
   ],
   "source": [
    "# Get training set length\n",
    "train_len = 0\n",
    "for pair, label in train_rlts:\n",
    "    try:\n",
    "        p1, p2 = [os.path.join(train_path, p) for p in pair]\n",
    "        p1_imgs = os.listdir(p1)\n",
    "        p2_imgs = os.listdir(p2)\n",
    "        train_len += 1\n",
    "    except FileNotFoundError:\n",
    "        continue\n",
    "\n",
    "train_len = train_len // dataset_period\n",
    "\n",
    "val_len = 0\n",
    "for pair, label in val_rlts:\n",
    "    try:\n",
    "        p1, p2 = [os.path.join(train_path, p) for p in pair]\n",
    "        p1_imgs = os.listdir(p1)\n",
    "        p2_imgs = os.listdir(p2)\n",
    "        val_len += 2*2\n",
    "    except FileNotFoundError:\n",
    "        continue\n",
    "\n",
    "val_len = val_len // eval_dataset_period\n",
    "\n",
    "print(f'Train set length: {train_len}')\n",
    "print(f'Valid set length: {val_len}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_distance_stats(predictions, labels):\n",
    "    val_pos = predictions[labels.astype(np.bool)]\n",
    "    val_neg = predictions[(1 - labels).astype(np.bool)]\n",
    "    val_pos_m, val_pos_s = np.mean(val_pos), np.std(val_pos)\n",
    "    val_neg_m, val_neg_s = np.mean(val_neg), np.std(val_neg)\n",
    "    \n",
    "    return val_pos_m, val_pos_s, val_neg_m, val_neg_s\n",
    "\n",
    "# Get upper and lower boundary for the predicted distances\n",
    "lower_lim = max(MARGIN - 2 * (MARGIN - margin_pos), 0.)\n",
    "upper_lim = min(MARGIN + 2 * (margin_neg - MARGIN), 2.)\n",
    "   \n",
    "def dist_to_prob(predictions):\n",
    "    y_prob = 1 - (np.clip(predictions, lower_lim, upper_lim) - lower_lim) / (upper_lim - lower_lim)\n",
    "    return y_prob\n",
    "  \n",
    "class MetricCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, logdir):\n",
    "        super(Callback, self).__init__()\n",
    "        if not os.path.exists(logdir):\n",
    "            os.makedirs(logdir)\n",
    "        self.train_writer = tf.summary.create_file_writer(logdir + '/train')\n",
    "        self.valid_writer = tf.summary.create_file_writer(logdir + '/valid')\n",
    "        self.class_encoded = {\n",
    "            0: 'not_related',\n",
    "            1: 'related'\n",
    "        }\n",
    "        \n",
    "    def tb_writer(self, items_to_write, wtype, epoch):\n",
    "        writer = self.train_writer if wtype == 'train' else self.valid_writer\n",
    "        \n",
    "        with writer.as_default():\n",
    "            for name, value in items_to_write.items():\n",
    "                tf.summary.scalar(name, value, epoch)\n",
    "            writer.flush()\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        val_true = []\n",
    "        val_pred = []\n",
    "        batches = batched_pairs(\n",
    "            val_rlts,\n",
    "            eval_batch_size,\n",
    "            eval_dataset_period,\n",
    "            input_shape,\n",
    "            preprocess,\n",
    "            shuffle=False,\n",
    "            slice_imgs=2\n",
    "        )\n",
    "        \n",
    "        for batch in batches:\n",
    "            val_pred.append(self.model.predict(batch[0]))\n",
    "            val_true.extend(list(batch[1]))\n",
    "        \n",
    "        val_true = np.array(val_true)\n",
    "        val_pred = np.concatenate(val_pred, axis=0).squeeze()\n",
    "        val_loss = contrastive_loss(K.constant(val_true), K.constant(val_pred))\n",
    "        \n",
    "        val_true = val_true.astype(int)\n",
    "        val_pos_m, val_pos_s, val_neg_m, val_neg_s = val_distance_stats(val_pred, val_true)\n",
    "        threshold = MARGIN\n",
    "        \n",
    "        # Precision and recall\n",
    "        val_cls = (val_pred < threshold).astype(int)\n",
    "        val_precision, val_recall, _, _ = precision_recall_fscore_support(val_true, val_cls, labels=[0, 1])\n",
    "        val_accuracy = accuracy_score(val_true, val_cls)\n",
    "        \n",
    "        # Area under ROC\n",
    "        val_probs = dist_to_prob(val_pred)\n",
    "        val_roc_auc = roc_auc_score(val_true, val_probs)\n",
    "        train_loss = logs['loss']\n",
    "        tb_logs = {}\n",
    "        tb_logs['train/loss'] = train_loss\n",
    "        \n",
    "        self.tb_writer(tb_logs, wtype='train', epoch=epoch)\n",
    "        \n",
    "        tb_logs = {}\n",
    "        tb_logs['valid/loss'] = val_loss\n",
    "        logs['val_loss'] = val_loss\n",
    "        for k, v in self.class_encoded.items():\n",
    "            tb_logs['valid/precision/' + v] = val_precision[k]\n",
    "            tb_logs['valid/recall/' + v] = val_recall[k]\n",
    "            tb_logs['valid/dist_mean/' + v] = val_pos_m if k else val_neg_m\n",
    "            tb_logs['valid/dist_std/' + v] = val_pos_s if k else val_neg_s\n",
    "        \n",
    "        tb_logs['valid/accuracy'] = val_accuracy\n",
    "        logs['val_roc_auc'] = val_roc_auc\n",
    "        tb_logs['valid/roc_auc'] = val_roc_auc\n",
    "\n",
    "        self.tb_writer(tb_logs, wtype='valid', epoch=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-24 23:19:23.430412: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session initializing.\n",
      "2021-09-24 23:19:23.430431: I tensorflow/core/profiler/lib/profiler_session.cc:141] Profiler session started.\n",
      "2021-09-24 23:19:23.431296: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1611] Profiler found 1 GPUs\n",
      "2021-09-24 23:19:23.447961: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcupti.so.11.4\n",
      "2021-09-24 23:19:23.554701: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session tear down.\n",
      "2021-09-24 23:19:23.554858: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1744] CUPTI activity buffer flushed\n"
     ]
    }
   ],
   "source": [
    "model_name = 'vggface_res50_2048_cos_005'\n",
    "\n",
    "#Save training configuration\n",
    "with open(f'configs/{model_name}.json', 'w') as f:\n",
    "    json.dump(train_config, f)\n",
    "\n",
    "logdir = os.path.join('logs', model_name)\n",
    "ckpt_dir = os.path.join('checkpoints', model_name)\n",
    "if not os.path.exists(ckpt_dir):\n",
    "    os.makedirs(ckpt_dir)\n",
    "\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "ckpt_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=os.path.join(ckpt_dir, 'model.hdf5'),\n",
    "    monitor='val_roc_auc',\n",
    "    save_best_only=True,\n",
    "    mode='max',\n",
    "    save_weights_only=False,\n",
    "    verbose=1,\n",
    ")\n",
    "metric_callback = MetricCallback(logdir)\n",
    "\n",
    "reduce_on_plateau = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.4,\n",
    "    patience=10,\n",
    "    verbose=1,\n",
    "    min_delta=1e-5,\n",
    "    min_lr = 5e-9\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n",
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-24 23:19:26.532213: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-09-24 23:19:26.552904: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 3600000000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n",
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-24 23:19:31.438564: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-09-24 23:19:32.594049: I tensorflow/stream_executor/cuda/cuda_dnn.cc:380] Loaded cuDNN version 8202\n",
      "2021-09-24 23:19:33.966891: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcublas.so.11\n",
      "2021-09-24 23:19:35.353791: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcublasLt.so.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "809/809 [==============================] - 233s 275ms/step - loss: 0.1081\n",
      "\n",
      "Epoch 00001: val_roc_auc improved from -inf to 0.55227, saving model to checkpoints/vggface_res50_2048_cos_005/model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/1000\n",
      "809/809 [==============================] - 225s 278ms/step - loss: 0.0243\n",
      "\n",
      "Epoch 00002: val_roc_auc improved from 0.55227 to 0.76979, saving model to checkpoints/vggface_res50_2048_cos_005/model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/1000\n",
      "809/809 [==============================] - 226s 279ms/step - loss: 0.0067\n",
      "\n",
      "Epoch 00003: val_roc_auc improved from 0.76979 to 0.79424, saving model to checkpoints/vggface_res50_2048_cos_005/model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/1000\n",
      "809/809 [==============================] - 225s 278ms/step - loss: 0.0055\n",
      "\n",
      "Epoch 00004: val_roc_auc improved from 0.79424 to 0.80903, saving model to checkpoints/vggface_res50_2048_cos_005/model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/1000\n",
      "809/809 [==============================] - 224s 277ms/step - loss: 0.0051\n",
      "\n",
      "Epoch 00005: val_roc_auc improved from 0.80903 to 0.81587, saving model to checkpoints/vggface_res50_2048_cos_005/model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/1000\n",
      "809/809 [==============================] - 225s 278ms/step - loss: 0.0048\n",
      "\n",
      "Epoch 00006: val_roc_auc improved from 0.81587 to 0.82312, saving model to checkpoints/vggface_res50_2048_cos_005/model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/1000\n",
      "809/809 [==============================] - 226s 279ms/step - loss: 0.0047\n",
      "\n",
      "Epoch 00007: val_roc_auc improved from 0.82312 to 0.82791, saving model to checkpoints/vggface_res50_2048_cos_005/model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/1000\n",
      "809/809 [==============================] - 224s 277ms/step - loss: 0.0045\n",
      "\n",
      "Epoch 00008: val_roc_auc improved from 0.82791 to 0.83191, saving model to checkpoints/vggface_res50_2048_cos_005/model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/1000\n",
      "809/809 [==============================] - 222s 274ms/step - loss: 0.0045\n",
      "\n",
      "Epoch 00009: val_roc_auc improved from 0.83191 to 0.83406, saving model to checkpoints/vggface_res50_2048_cos_005/model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/1000\n",
      "809/809 [==============================] - 219s 270ms/step - loss: 0.0043\n",
      "\n",
      "Epoch 00010: val_roc_auc improved from 0.83406 to 0.83832, saving model to checkpoints/vggface_res50_2048_cos_005/model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/1000\n",
      "809/809 [==============================] - 218s 269ms/step - loss: 0.0043\n",
      "\n",
      "Epoch 00011: val_roc_auc did not improve from 0.83832\n",
      "Epoch 12/1000\n",
      "809/809 [==============================] - 219s 271ms/step - loss: 0.0042\n",
      "\n",
      "Epoch 00012: val_roc_auc improved from 0.83832 to 0.83912, saving model to checkpoints/vggface_res50_2048_cos_005/model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/1000\n",
      " 99/809 [==>...........................] - ETA: 3:15 - loss: 0.0042"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_888979/4185579125.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m model.fit(\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mrepeat_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_rlts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_period\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1186\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1188\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1189\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \"\"\"\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    315\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    335\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    373\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1099\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1101\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1102\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 867\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    868\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 867\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    868\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    513\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \"\"\"\n\u001b[1;32m   1093\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1094\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1095\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1058\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1060\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1061\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def repeat_generator(rlts, batch_size, dataset_period, input_shape, preprocess):\n",
    "    while True:\n",
    "        for e in batched_pairs(rlts, batch_size, dataset_period, input_shape, preprocess):\n",
    "            yield e\n",
    "            \n",
    "model.fit(\n",
    "    repeat_generator(train_rlts, batch_size, dataset_period, input_shape, preprocess),\n",
    "    epochs=epochs,\n",
    "    steps_per_epoch=train_len//batch_size,\n",
    "    callbacks=[metric_callback, ckpt_callback, reduce_on_plateau]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load submission pairs\n",
    "submission_path = 'data/sample_submission.csv'\n",
    "submission_df = pd.read_csv(submission_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models\n",
    "ckpt_path = 'checkpoints/vggface_res50_512_cos_002/model.hdf5'\n",
    "model.load_weights(ckpt_path)\n",
    "# model = keras.models.load_model(ckpt_path, custom_objects={'contrastive_loss': contrastive_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over submission pairs\n",
    "submission_df = submission_df.astype({'is_related': 'float'})\n",
    "is_related = submission_df['is_related']\n",
    "predictions = []\n",
    "for idx, row in submission_df.iterrows():\n",
    "    # Load images\n",
    "    img_pair = row['img_pair']\n",
    "    img1_name, img2_name = img_pair.split('-')\n",
    "    img1_path = os.path.join('data/test', img1_name)\n",
    "    img2_path = os.path.join('data/test', img2_name)\n",
    "    img1 = image.load_img(img1_path)\n",
    "    img2 = image.load_img(img2_path)\n",
    "    img1 = preprocess(np.array(img1).astype('float32'))\n",
    "    img2 = preprocess(np.array(img2).astype('float32'))\n",
    "    img1 = np.expand_dims(img1, 0)\n",
    "    img2 = np.expand_dims(img2, 0)\n",
    "    \n",
    "    # Do an inference, and calculate probability according to distance\n",
    "    y_pred = model.predict({'input_1':img1, 'input_2':img2})\n",
    "    y_pred = y_pred.squeeze()\n",
    "    y_prob = dist_to_prob(y_pred)\n",
    "    predictions.append(y_prob)\n",
    "    is_related[idx] = y_prob\n",
    "    \n",
    "    # Print step\n",
    "    if idx % 100 == 0:\n",
    "        print(f'Processed rows: {idx}')\n",
    "        \n",
    "submission_df.to_csv(f'submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(30, 8))\n",
    "plt.hist(predictions, 1000)\n",
    "plt.locator_params(axis='x', nbins=100)\n",
    "plt.xticks(rotation = 45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.read_csv(submission_path)\n",
    "is_related = submission_df['is_related']\n",
    "# print(is_related.sum())\n",
    "for i, pred in enumerate(predictions):\n",
    "    if pred < 0.149:\n",
    "        is_related[i] = 1\n",
    "submission_df.to_csv(f'submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
