{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-18 17:39:16.037002: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import tensorflow.keras as keras\n",
    "import random\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "random.seed(123)\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "input_shape = (32, 32, 3)\n",
    "image_size = 72  # We'll resize input images to this size\n",
    "patch_size = 6  # Size of the patches to be extract from the input images\n",
    "num_patches = (image_size // patch_size) ** 2\n",
    "projection_dim = 64\n",
    "num_heads = 4\n",
    "transformer_units = [\n",
    "    projection_dim * 2,\n",
    "    projection_dim,\n",
    "]  # Size of the transformer layers\n",
    "transformer_layers = 8\n",
    "mlp_head_units = [2048, 1024]  # Size of the dense layers of the final classifier\n",
    "\n",
    "def mlp(x, hidden_units, dropout_rate):\n",
    "    for units in hidden_units:\n",
    "        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "    return x\n",
    "\n",
    "class Patches(layers.Layer):\n",
    "    def __init__(self, patch_size):\n",
    "        super(Patches, self).__init__()\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def call(self, images):\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        patches = tf.image.extract_patches(\n",
    "            images=images,\n",
    "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
    "            strides=[1, self.patch_size, self.patch_size, 1],\n",
    "            rates=[1, 1, 1, 1],\n",
    "            padding=\"VALID\",\n",
    "        )\n",
    "        patch_dims = patches.shape[-1]\n",
    "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
    "        return patches\n",
    "\n",
    "class PatchEncoder(layers.Layer):\n",
    "    def __init__(self, num_patches, projection_dim):\n",
    "        super(PatchEncoder, self).__init__()\n",
    "        self.num_patches = num_patches\n",
    "        self.projection = layers.Dense(units=projection_dim)\n",
    "        self.position_embedding = layers.Embedding(\n",
    "            input_dim=num_patches, output_dim=projection_dim\n",
    "        )\n",
    "\n",
    "    def call(self, patch):\n",
    "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
    "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
    "        return encoded\n",
    "\n",
    "def vit(input_shape):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # Create patches.\n",
    "    patches = Patches(patch_size)(inputs)\n",
    "    # Encode patches.\n",
    "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
    "\n",
    "    # Create multiple layers of the Transformer block.\n",
    "    for _ in range(transformer_layers):\n",
    "        # Layer normalization 1.\n",
    "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "        # Create a multi-head attention layer.\n",
    "        attention_output = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
    "        )(x1, x1)\n",
    "        # Skip connection 1.\n",
    "        x2 = layers.Add()([attention_output, encoded_patches])\n",
    "        # Layer normalization 2.\n",
    "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "        # MLP.\n",
    "        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n",
    "        # Skip connection 2.\n",
    "        encoded_patches = layers.Add()([x3, x2])\n",
    "\n",
    "    # Create a [batch_size, projection_dim] tensor.\n",
    "    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "    representation = layers.Flatten()(representation)\n",
    "    representation = layers.Dropout(0.5)(representation)\n",
    "    # Add MLP.\n",
    "    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n",
    "    # Classify outputs.\n",
    "#     logits = layers.Dense(num_classes)(features)\n",
    "    # Create the Keras model.\n",
    "    model = keras.Model(inputs=inputs, outputs=features)\n",
    "    return model\n",
    "\n",
    "vit_classifier = vit(input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The input embeddings\n",
    "\n",
    "The data in the input pickle file is stored in a dictionary structure:\n",
    "```\n",
    "{\n",
    "    [\n",
    "        'FAMILY_ID/PERSON_ID': [EMB_1, EMB_2...EMB_N],\n",
    "        .\n",
    "        .\n",
    "        .\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The keys examples: ['F0475/MID3', 'F0475/MID7', 'F0475/MID6', 'F0475/MID4', 'F0475/MID2']\n",
      "Embeddings shape: (512,)\n"
     ]
    }
   ],
   "source": [
    "with open('../data/train_img_embeddings.pkl', 'rb') as f:\n",
    "       train_embeddings = pickle.load(f)\n",
    "print(f'The keys examples: {list(train_embeddings.keys())[:5]}')\n",
    "\n",
    "embedding_shape = list(list(train_embeddings.values())[0].values())[0].shape\n",
    "print(f'Embeddings shape: {embedding_shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training pairs generating\n",
    "\n",
    "Available training pairs from csv files are splitted to train - validation sets. Those pairs are positive(there is blood relation). For each set(train/valid) we additionally generate negative pairs.\n",
    "\n",
    "Positive pairs are generated according to the input csv file. For each person of positive pair we create one negative pair.\n",
    "In total we'll have twice more negative than positive pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_image_pair(pair):\n",
    "    '''\n",
    "    Create pair of embeddings.\n",
    "    \n",
    "    Arguments:\n",
    "    p1, p2 -- paths to persons' images directories (familyID/personID)\n",
    "    \n",
    "    Returns:\n",
    "    pairs -- array of image pairs, pairing is alligned to smaller number of images\n",
    "    '''\n",
    "        \n",
    "    p1, p2 = pair\n",
    "    \n",
    "    dir1 = train_embeddings[p1].values()\n",
    "    dir2 = train_embeddings[p2].values()\n",
    "    \n",
    "    for e1 in dir1:\n",
    "        for e2 in dir2:\n",
    "            yield np.concatenate([e1, e2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairs_set(input_pairs):\n",
    "    for pair, label in input_pairs:\n",
    "        try:\n",
    "            embs = make_image_pair(pair)\n",
    "            for emb in embs:\n",
    "                yield emb, label\n",
    "        except KeyError:\n",
    "            continue\n",
    "\n",
    "def batched_pairs(input_pairs, batch_size, dataset_period):\n",
    "    embs = []\n",
    "    labels = []\n",
    "    counter = 0\n",
    "    for example in pairs_set(input_pairs):\n",
    "        # Get every nth sample\n",
    "        counter += 1\n",
    "        if counter % dataset_period:\n",
    "            continue\n",
    "        \n",
    "        emb, label = example\n",
    "        embs.append(emb)\n",
    "        labels.append(np.array(label, dtype=int))\n",
    "        if len(labels) == batch_size:\n",
    "            yield np.array(embs), np.array(labels)\n",
    "            embs, labels = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../train_val_set.json', 'r') as f:\n",
    "    train_val_set = json.load(f)\n",
    "\n",
    "train_rlt_list, neg_train_rltshps, valid_rlt_list, neg_valid_rltshps = list(train_val_set.values())\n",
    "train_rlts = list(zip(train_rlt_list + neg_train_rltshps, [True]*len(train_rlt_list) + [False]*len(neg_train_rltshps)))\n",
    "val_rlts = list(zip(valid_rlt_list + neg_valid_rltshps, [True]*len(valid_rlt_list) + [False]*len(neg_valid_rltshps)))\n",
    "\n",
    "random.shuffle(train_rlts)\n",
    "random.shuffle(val_rlts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_distance_stats(predictions, labels):\n",
    "    val_pos = predictions[labels.astype(np.bool)]\n",
    "    val_neg = predictions[(1 - labels).astype(np.bool)]\n",
    "    val_pos_m, val_pos_s = np.mean(val_pos), np.std(val_pos)\n",
    "    val_neg_m, val_neg_s = np.mean(val_neg), np.std(val_neg)\n",
    "    \n",
    "    return val_pos_m, val_pos_s, val_neg_m, val_neg_s\n",
    "  \n",
    "class MetricCallback(xgb.callback.TrainingCallback):\n",
    "    def __init__(self, logdir):\n",
    "        if not os.path.exists(logdir):\n",
    "            os.makedirs(logdir)\n",
    "        self.train_writer = tf.summary.create_file_writer(logdir + '/train')\n",
    "        self.valid_writer = tf.summary.create_file_writer(logdir + '/valid')\n",
    "        self.class_encoded = {\n",
    "            0: 'not_related',\n",
    "            1: 'related'\n",
    "        }\n",
    "        \n",
    "    def tb_writer(self, items_to_write, wtype, epoch):\n",
    "        writer = self.train_writer if wtype == 'train' else self.valid_writer\n",
    "        \n",
    "        with writer.as_default():\n",
    "            for name, value in items_to_write.items():\n",
    "                tf.summary.scalar(name, value, epoch)\n",
    "            writer.flush()\n",
    "        \n",
    "    def after_iteration(self, model, epoch, evals_log):\n",
    "        val_true = []\n",
    "        val_pred = []\n",
    "        for batch in batched_pairs(val_rlts, batch_size, eval_dataset_period):\n",
    "            val_pred.append(model.predict(xgb.DMatrix(batch[0])))\n",
    "            val_true.extend(list(batch[1]))\n",
    "        \n",
    "        val_true = np.array(val_true).astype(int)\n",
    "        val_pred = np.concatenate(val_pred, axis=0)\n",
    "        val_pred = np.around(val_pred)\n",
    "        \n",
    "        # Precision and recall\n",
    "        valid_precision, valid_recall, _, _ = precision_recall_fscore_support(val_true, val_pred, labels=[0, 1])\n",
    "        valid_accuracy = accuracy_score(val_true, val_pred)\n",
    "        \n",
    "        logs = {}\n",
    "        for k, v in self.class_encoded.items():\n",
    "            logs['valid/precision/' + v] = valid_precision[k]\n",
    "            logs['valid/recall/' + v] = valid_recall[k]\n",
    "        \n",
    "        logs['valid/accuracy'] = valid_accuracy\n",
    "\n",
    "        self.tb_writer(logs, wtype='valid', epoch=epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run tensorboard plugin in order to track changes of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir=./logs/xgboost --port=7008"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2000\n",
    "batch_size = 32\n",
    "dataset_period = 2\n",
    "eval_dataset_period = 12\n",
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'mobile_xgboost_002'\n",
    "logdir = os.path.join('logs/xgboost', model_name)\n",
    "metric_callback = MetricCallback(logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset length: (166432,)\n",
      "Number of negatives: 133346\n"
     ]
    }
   ],
   "source": [
    "train_x = []\n",
    "train_y = []\n",
    "for batch in batched_pairs(train_rlts, batch_size, dataset_period):\n",
    "    train_x.append(batch[0])\n",
    "    train_y.append(batch[1])\n",
    "train_x = np.concatenate(train_x, axis=0)\n",
    "train_y = np.concatenate(train_y)\n",
    "\n",
    "print(f'Original dataset length: {train_y.shape}')\n",
    "print(f'Number of negatives: {(1 - train_y).sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_cls = xgb.XGBClassifier(n_estimators=epochs,\n",
    "                            max_depth=70,\n",
    "                            learning_rate=lr,\n",
    "                            use_label_encoder=False,\n",
    "                            scale_pos_weight=50)\n",
    "\n",
    "xgb_cls.fit(train_x, train_y, verbose=True, callbacks=[metric_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load submission pairs\n",
    "submission_path = 'data/sample_submission.csv'\n",
    "submission_df = pd.read_csv(submission_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models\n",
    "ckpt_path = 'checkpoints/model_6/weights.70-0.11.hdf5'\n",
    "model.load_weights(ckpt_path)\n",
    "embedder = FaceNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the threshold according to validation ds\n",
    "val_pred = model.predict([val_pairs[:, 0], val_pairs[:, 1]])\n",
    "val_pos_m, val_pos_s, val_neg_m, val_neg_s = val_distance_stats(val_pred, val_labels.astype(np.int))\n",
    "threshold = ((val_pos_m + val_pos_s) + (val_neg_m - val_neg_s)) / 2\n",
    "\n",
    "# Iterate over submission pairs\n",
    "is_related = submission_df['is_related']\n",
    "predictions = []\n",
    "for idx, row in submission_df.iterrows():\n",
    "    # Load images\n",
    "    img_pair = row['img_pair']\n",
    "    img1_name, img2_name = img_pair.split('-')\n",
    "    img1_path = os.path.join('data/test', img1_name)\n",
    "    img2_path = os.path.join('data/test', img2_name)\n",
    "    img1 = image.load_img(img1_path)\n",
    "    img2 = image.load_img(img2_path)\n",
    "    img1 = np.array(img1).astype('float32')\n",
    "    img2 = np.array(img2).astype('float32')\n",
    "    \n",
    "    # Get FaceNet embeddings\n",
    "    embedding1 = embedder.embeddings([img1])\n",
    "    embedding2 = embedder.embeddings([img2])\n",
    "    \n",
    "    # Do an inference, if distance is smaller than threshold\n",
    "    # then there is the relation\n",
    "    y_pred = model.predict([embedding1, embedding2])\n",
    "    predictions.append(y_pred[0])\n",
    "    if y_pred.squeeze() < threshold:\n",
    "        is_related[idx] = 1\n",
    "    \n",
    "    # Print step\n",
    "    if idx % 100 == 0:\n",
    "        print(f'Processed rows: {idx}')\n",
    "        \n",
    "submission_df.to_csv(f'submission_{model_name}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(predictions, 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thr = 0.85\n",
    "for i, p in enumerate(predictions):\n",
    "    if p < thr:\n",
    "        is_related[i] = 1\n",
    "    else:\n",
    "        is_related[i] = 0\n",
    "submission_df.to_csv(f'submission_test.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
