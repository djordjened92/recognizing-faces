{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from datetime import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "from keras.optimizers import RMSprop, SGD, Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.preprocessing import image\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.callbacks import Callback, LearningRateScheduler\n",
    "from keras.layers import Input, Flatten, Dense, Dropout, Lambda, Conv1D, Attention, GlobalAveragePooling1D, BatchNormalization\n",
    "from keras_facenet import FaceNet\n",
    "\n",
    "tf.random.set_seed(12)\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The input embeddings\n",
    "\n",
    "The data in the input pickle file is stored in a dictionary structure:\n",
    "```\n",
    "{\n",
    "    [\n",
    "        'FAMILY_ID/PERSON_ID': [EMB_1, EMB_2...EMB_N],\n",
    "        .\n",
    "        .\n",
    "        .\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The keys examples: ['F0002\\\\MID1', 'F0002\\\\MID2', 'F0002\\\\MID3', 'F0005\\\\MID1', 'F0005\\\\MID2']\n",
      "Embeddings shape: (512,)\n"
     ]
    }
   ],
   "source": [
    "with open('data/train_img_embeddings.pkl', 'rb') as f:\n",
    "       train_embeddings = pickle.load(f)\n",
    "print(f'The keys examples: {list(train_embeddings.keys())[:5]}')\n",
    "\n",
    "embedding_shape = list(train_embeddings.values())[0][0].shape\n",
    "print(f'Embeddings shape: {embedding_shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training pairs generating\n",
    "\n",
    "Available training pairs from csv files are splitted to train - validation sets. Those pairs are positive(there is blood relation). For each set(train/valid) we additionally generate negative pairs.\n",
    "\n",
    "Positive pairs are generated according to the input csv file. For each person of positive pair we create one negative pair.\n",
    "In total we'll have twice more negative than positive pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_negative_paris(train_rltshps):\n",
    "    '''\n",
    "    Create negative pairs: for each person of positive pair create negative pair\n",
    "    by picking some random person with whome they are not in the relationship.\n",
    "    '''\n",
    "    \n",
    "    all_persons = train_rltshps['p1'].unique().tolist() + \\\n",
    "                    train_rltshps['p2'].unique().tolist()\n",
    "    n = len(all_persons)\n",
    "    negative_rltshps = []\n",
    "    train_rltshps = [set(e) for e in zip(train_rltshps['p1'], train_rltshps['p2'])]\n",
    "    \n",
    "    for pair_set in train_rltshps:\n",
    "        p1, p2 = list(pair_set)\n",
    "        \n",
    "        # Add negative pairs\n",
    "        # For the person p1\n",
    "        rnd_idx = np.random.randint(n)\n",
    "        negative_sample = all_persons[rnd_idx]\n",
    "                           \n",
    "        while(negative_sample == p1 or \\\n",
    "              (set([p1, negative_sample]) in train_rltshps) or \\\n",
    "              (set([p1, negative_sample]) in negative_rltshps)):\n",
    "            rnd_idx = np.random.randint(n)\n",
    "            negative_sample = all_persons[rnd_idx]\n",
    "            \n",
    "        negative_rltshps.append(set([p1, negative_sample]))\n",
    "\n",
    "        # For the person p2\n",
    "        rnd_idx = np.random.randint(n)\n",
    "        negative_sample = all_persons[rnd_idx]\n",
    "\n",
    "        while(negative_sample == p2 or \\\n",
    "              (set([p2, negative_sample]) in train_rltshps) or \\\n",
    "              (set([p2, negative_sample]) in negative_rltshps)):\n",
    "            rnd_idx = np.random.randint(n)\n",
    "            negative_sample = all_persons[rnd_idx]\n",
    "            \n",
    "        negative_rltshps.append(set([p2, negative_sample]))\n",
    "        \n",
    "    return pd.DataFrame(negative_rltshps, columns=['p1', 'p2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pairs(p1, p2):\n",
    "    '''\n",
    "    Create pair of embeddings.\n",
    "    \n",
    "    Arguments:\n",
    "    p1, p2 -- paths to persons' images directories (familyID/personID)\n",
    "    \n",
    "    Returns:\n",
    "    pairs -- array of image pairs, pairing is alligned to smaller number of images\n",
    "    '''\n",
    "    pairs = []\n",
    "    img_path1 = p1.replace('/', '\\\\')\n",
    "    img_path2 = p2.replace('/', '\\\\')\n",
    "    \n",
    "    dir1 = np.expand_dims(train_embeddings[img_path1], axis=-1)\n",
    "    dir2 = np.expand_dims(train_embeddings[img_path2], axis=-1)\n",
    "    \n",
    "    for i in range(len(dir1)):\n",
    "        for j in range(len(dir2)):\n",
    "            pairs.append([dir1[i], dir2[j]])\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairs_set(input_pairs, positive=True):\n",
    "    '''\n",
    "    Generate pairs of images of persons.\n",
    "    \n",
    "    Arguments:\n",
    "    input_pairs -- pandas DataFrame with pair paths\n",
    "    positive -- if pair is positive (persons are related)\n",
    "    \n",
    "    Returns:\n",
    "    train_pairs -- array of pairs of embeddings\n",
    "    labels -- labels for each pair, 1 for positive(in blood relation) and 0 for negative\n",
    "    '''\n",
    "    pairs = []\n",
    "    labels = []\n",
    "    errors = 0\n",
    "    for idx, row in input_pairs.iterrows():\n",
    "        try:\n",
    "            new_pairs = make_pairs(row['p1'], row['p2'])\n",
    "            pairs += new_pairs\n",
    "            label = 1. if positive else 0.\n",
    "            labels += [label] * len(new_pairs)  \n",
    "        except KeyError:\n",
    "            errors += 1\n",
    "    print(f'\\nThere are {errors} key errors of relationships.')\n",
    "    return pairs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F0002/MID1</td>\n",
       "      <td>F0002/MID3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F0002/MID2</td>\n",
       "      <td>F0002/MID3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F0005/MID1</td>\n",
       "      <td>F0005/MID2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F0005/MID3</td>\n",
       "      <td>F0005/MID2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F0009/MID1</td>\n",
       "      <td>F0009/MID4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           p1          p2\n",
       "0  F0002/MID1  F0002/MID3\n",
       "1  F0002/MID2  F0002/MID3\n",
       "2  F0005/MID1  F0005/MID2\n",
       "3  F0005/MID3  F0005/MID2\n",
       "4  F0009/MID1  F0009/MID4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read relatives' pairs\n",
    "train_rltshps = pd.read_csv(\"data/train_relationships.csv\")\n",
    "train_rltshps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create negative relationships\n",
    "negative_rltshps = create_negative_paris(train_rltshps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle rows in pandas DataFrame\n",
    "train_rltshps = train_rltshps.sample(frac=1, random_state=123).reset_index(drop=True)\n",
    "negative_rltshps = negative_rltshps.sample(frac=1, random_state=123).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3167, 2)\n",
      "(431, 2)\n",
      "(6333, 2)\n",
      "(863, 2)\n"
     ]
    }
   ],
   "source": [
    "# Create training and validation sets\n",
    "# Split positive pairs\n",
    "VAL_FACTOR = 0.12\n",
    "val_threshold = int(len(train_rltshps.index) * VAL_FACTOR)\n",
    "val_rltshps = train_rltshps.iloc[:val_threshold]\n",
    "train_rltshps = train_rltshps.iloc[val_threshold:]\n",
    "print(train_rltshps.shape)\n",
    "print(val_rltshps.shape)\n",
    "\n",
    "# Split negative pairs\n",
    "val_threshold = int(len(negative_rltshps.index) * VAL_FACTOR)\n",
    "val_neg_rltshps = negative_rltshps.iloc[:val_threshold]\n",
    "train_neg_rltshps = negative_rltshps.iloc[val_threshold:]\n",
    "print(train_neg_rltshps.shape)\n",
    "print(val_neg_rltshps.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "There are 204 key errors of relationships.\n",
      "\n",
      "There are 27 key errors of relationships.\n",
      "\n",
      "There are 426 key errors of relationships.\n",
      "\n",
      "There are 61 key errors of relationships.\n"
     ]
    }
   ],
   "source": [
    "# Load embeddings for splitted data\n",
    "train_pairs, train_labels = pairs_set(train_rltshps, True)\n",
    "val_pairs, val_labels = pairs_set(val_rltshps, True)\n",
    "\n",
    "train_neg_pairs, train_neg_labels = pairs_set(train_neg_rltshps, False)\n",
    "val_neg_pairs, val_neg_labels = pairs_set(val_neg_rltshps, False)\n",
    "\n",
    "train_pairs = np.array(train_pairs + train_neg_pairs)\n",
    "train_labels = np.array(train_labels + train_neg_labels)\n",
    "val_pairs = np.array(val_pairs + val_neg_pairs)\n",
    "val_labels = np.array(val_labels + val_neg_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(329529, 2, 512, 1)\n",
      "(46301, 2, 512, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_pairs.shape)\n",
    "print(val_pairs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Siamise network\n",
    "\n",
    "Initial experimenting is done with conv1D deep neural network, as additional option for experimenting there is simple attention module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv1D_model(input_shape, l2_value, dropout):\n",
    "    '''\n",
    "    Create deep Keras model.\n",
    "    \n",
    "    Arguments:\n",
    "    input_shape -- shape of the input layer\n",
    "    \n",
    "    Returns:\n",
    "    Model -- Keras model\n",
    "    '''\n",
    "    def residual(x, kernel, l2_value, activation='relu'):\n",
    "        x1 = Conv1D(x.shape[-1], kernel, kernel_regularizer=l2(l2_value), activation=activation, padding='same')(x)\n",
    "        x1 = BatchNormalization()(x1)\n",
    "        return x + x1\n",
    "    \n",
    "    input = Input(shape=input_shape)\n",
    "    x = Conv1D(input.shape[1] // 64, 7, kernel_regularizer=l2(l2_value), activation='tanh')(input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    x = residual(x, 7, l2_value, 'tanh')\n",
    "    \n",
    "    x = Conv1D(input.shape[1] // 64, 11, kernel_regularizer=l2(l2_value), activation='tanh')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    x = residual(x, 11, l2_value, 'tanh')\n",
    "    \n",
    "    x = Conv1D(input.shape[1] // 32, 17, kernel_regularizer=l2(l2_value), activation='tanh')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    x = residual(x, 17, l2_value, 'tanh')\n",
    "    \n",
    "    x = Conv1D(input.shape[1] // 32, 17, kernel_regularizer=l2(l2_value), activation='tanh')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    x = residual(x, 17, l2_value, 'tanh')\n",
    "    \n",
    "    x = Conv1D(input.shape[1] // 16, 19, kernel_regularizer=l2(l2_value), activation='tanh')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    x = residual(x, 19, l2_value, 'tanh')\n",
    "    \n",
    "    x = Conv1D(input.shape[1] // 16, 19, kernel_regularizer=l2(l2_value), activation='tanh')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    x = residual(x, 19, l2_value, 'tanh')\n",
    "    \n",
    "    x = Conv1D(input.shape[1] // 8, 19, kernel_regularizer=l2(l2_value), activation='tanh')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    x = residual(x, 19, l2_value, 'tanh')\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    \n",
    "    x = Dense(input.shape[1] // 16, kernel_regularizer=l2(l2_value), activation='relu')(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    return Model(input, x)\n",
    "\n",
    "def attention_model(input_shape, train_mode=True):\n",
    "    '''\n",
    "    Inspired by code example:\n",
    "    https://www.tensorflow.org/api_docs/python/tf/keras/layers/Attention\n",
    "    '''\n",
    "    input = Input(shape=input_shape, dtype='int32')\n",
    "    query_input = value_input = K.squeeze(input, -1)\n",
    "    \n",
    "    # Embedding lookup.\n",
    "    token_embedding = tf.keras.layers.Embedding(input_dim=input_shape[1], output_dim=64)\n",
    "    # Query embeddings of shape [batch_size, Tq, dimension].\n",
    "    query_embeddings = token_embedding(query_input)\n",
    "    # Value embeddings of shape [batch_size, Tv, dimension].\n",
    "    value_embeddings = token_embedding(value_input)\n",
    "\n",
    "    query_seq_encoding = Conv1D(input.shape[1] // 4, 5, activation='relu', padding='same')(\n",
    "        query_embeddings)\n",
    "    value_seq_encoding = Conv1D(input.shape[1] // 4, 5, activation='relu', padding='same')(\n",
    "        value_embeddings)\n",
    "    \n",
    "    query_value_attention_seq = tf.keras.layers.Attention()(\n",
    "        [query_seq_encoding, value_seq_encoding], training=train_mode)\n",
    "    \n",
    "    # Reduce over the sequence axis to produce encodings of shape\n",
    "    # [batch_size, filters].\n",
    "    query_encoding = tf.keras.layers.GlobalAveragePooling1D()(\n",
    "        query_seq_encoding)\n",
    "    query_value_attention = tf.keras.layers.GlobalAveragePooling1D()(\n",
    "        query_value_attention_seq)\n",
    "    \n",
    "    # Concatenate query and document encodings to produce a DNN input layer.\n",
    "    attn_out_layer = tf.keras.layers.Concatenate()([query_encoding, query_value_attention])\n",
    "    return Model(input, attn_out_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss and metrics functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "MARGIN = 1.\n",
    "\n",
    "def euclidean_distance(vectors):\n",
    "    x, y = vectors\n",
    "    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\n",
    "    return K.sqrt(K.maximum(sum_square, K.epsilon()))\n",
    "\n",
    "def cosine_similarity(vectors):\n",
    "    x, y = vectors\n",
    "    x_norm = tf.norm(x, axis=1)\n",
    "    y_norm = tf.norm(y, axis=1)\n",
    "    x_y_dot = tf.einsum('ij,ij->i', x, y)\n",
    "    cos_sim = x_y_dot / (x_norm * y_norm + K.epsilon())\n",
    "    return 1. - cos_sim\n",
    "\n",
    "def eucl_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)\n",
    "\n",
    "def contrastive_loss_euc(y_true, y_pred):\n",
    "    '''\n",
    "    Contrastive loss from Hadsell-et-al.'06\n",
    "    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    '''\n",
    "    square_pred = K.square(y_pred)\n",
    "    margin_square = K.square(K.maximum(MARGIN - y_pred, 0))\n",
    "    return K.mean(y_true * square_pred + (1 - y_true) * margin_square)\n",
    "\n",
    "def contrastive_loss_cos(y_true, y_pred):\n",
    "    margin_dist = K.maximum(MARGIN - y_pred, 0)\n",
    "    return K.mean(y_true * y_pred + (1 - y_true) * margin_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-5\n",
    "l2_value = 1e-7\n",
    "dropout = 0.05\n",
    "epochs = 2000\n",
    "batch_size = 8\n",
    "dataset_period = 2\n",
    "# 'euclidian' or 'cosine'\n",
    "distance_type = 'cosine'\n",
    "\n",
    "# Learning rate scheduler\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 50:\n",
    "        return lr\n",
    "    elif epoch < 100:\n",
    "        return lr / 2\n",
    "    elif epoch < 200:\n",
    "        return lr / 5\n",
    "    else:\n",
    "        return lr / 10\n",
    "    \n",
    "lr_callback = LearningRateScheduler(scheduler)\n",
    "\n",
    "# Create dictionary of parameters for saving configuration\n",
    "train_config = {}\n",
    "for name in ['learning_rate','l2_value','dropout','epochs','batch_size','dataset_period', 'distance_type']:\n",
    "    train_config[name] = eval(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pairs = train_pairs[::dataset_period,...]\n",
    "train_labels = train_labels[::dataset_period,...]\n",
    "val_pairs = val_pairs[::dataset_period,...]\n",
    "val_labels = val_labels[::dataset_period,...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input has 512 embeddings\n",
    "base_network = conv1D_model(train_pairs.shape[-2:], l2_value, dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 512, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 506, 8)       64          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 506, 8)       32          conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 506, 8)       0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 506, 8)       456         dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 506, 8)       32          conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2 (TensorFlowOp [(None, 506, 8)]     0           dropout[0][0]                    \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 496, 8)       712         tf_op_layer_AddV2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 496, 8)       32          conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 496, 8)       0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 496, 8)       712         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 496, 8)       32          conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_1 (TensorFlow [(None, 496, 8)]     0           dropout_1[0][0]                  \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 480, 16)      2192        tf_op_layer_AddV2_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 480, 16)      64          conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 480, 16)      0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 480, 16)      4368        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 480, 16)      64          conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_2 (TensorFlow [(None, 480, 16)]    0           dropout_2[0][0]                  \n",
      "                                                                 batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 464, 16)      4368        tf_op_layer_AddV2_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 464, 16)      64          conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 464, 16)      0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 464, 16)      4368        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 464, 16)      64          conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_3 (TensorFlow [(None, 464, 16)]    0           dropout_3[0][0]                  \n",
      "                                                                 batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 446, 32)      9760        tf_op_layer_AddV2_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 446, 32)      128         conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 446, 32)      0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 446, 32)      19488       dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 446, 32)      128         conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_4 (TensorFlow [(None, 446, 32)]    0           dropout_4[0][0]                  \n",
      "                                                                 batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 428, 32)      19488       tf_op_layer_AddV2_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 428, 32)      128         conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 428, 32)      0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 428, 32)      19488       dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 428, 32)      128         conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_5 (TensorFlow [(None, 428, 32)]    0           dropout_5[0][0]                  \n",
      "                                                                 batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 410, 64)      38976       tf_op_layer_AddV2_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 410, 64)      256         conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 410, 64)      0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 410, 64)      77888       dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 410, 64)      256         conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_6 (TensorFlow [(None, 410, 64)]    0           dropout_6[0][0]                  \n",
      "                                                                 batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 26240)        0           tf_op_layer_AddV2_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 32)           839712      flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 32)           0           dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 1,043,448\n",
      "Trainable params: 1,042,744\n",
      "Non-trainable params: 704\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of Siamese network\n",
    "input1 = Input(shape=embedding_shape[0])\n",
    "input2 = Input(shape=embedding_shape[0])\n",
    "processed1 = base_network(input1)\n",
    "processed2 = base_network(input2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_losses = {\n",
    "    'euclidian': {\n",
    "        'dist': euclidean_distance,\n",
    "        'loss': contrastive_loss_euc\n",
    "    },\n",
    "    'cosine': {\n",
    "        'dist': cosine_similarity,\n",
    "        'loss': contrastive_loss_cos\n",
    "    }\n",
    "}\n",
    "distance = Lambda(distances_losses[distance_type]['dist'],\n",
    "                  output_shape=eucl_dist_output_shape)([processed1, processed2])\n",
    "\n",
    "model = Model([input1, input2], distance)\n",
    "optimizer = RMSprop(learning_rate=learning_rate)\n",
    "model.compile(loss=distances_losses[distance_type]['loss'], optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run tensorboard plugin in order to track changes of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 7007 (pid 857), started 6:24:59 ago. (Use '!kill 857' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-f00a9e7224ddb4ad\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-f00a9e7224ddb4ad\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 7007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=./logs --port=7007"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, model_name, logs_dir='./logs'):\n",
    "        super(Callback, self).__init__()\n",
    "        logdir = os.path.join(logs_dir, model_name)\n",
    "        if not os.path.exists(logdir):\n",
    "            os.makedirs(logdir)\n",
    "        self.train_writer = tf.summary.create_file_writer(logdir + '/train')\n",
    "        self.valid_writer = tf.summary.create_file_writer(logdir + '/valid')\n",
    "        self.step_number = 0\n",
    "        \n",
    "    def tb_writer(self, items_to_write, wtype):\n",
    "        writer = self.train_writer if wtype == 'train' else self.valid_writer\n",
    "        \n",
    "        with writer.as_default():\n",
    "            for name, value in items_to_write.items():\n",
    "                tf.summary.scalar(name, value, self.step_number)\n",
    "            writer.flush()\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        class_encoded = {\n",
    "            0: 'not_related',\n",
    "            1: 'related'\n",
    "        }\n",
    "        \n",
    "        train_pred = self.model.predict([train_pairs[:, 0], train_pairs[:, 1]])\n",
    "        train_true = train_labels.astype(int)\n",
    "        train_pos = train_pred[train_true.astype(np.bool)]\n",
    "        train_neg = train_pred[(1 - train_true).astype(np.bool)]\n",
    "        train_pos_m, train_pos_s = np.mean(train_pos), np.std(train_pos)\n",
    "        train_neg_m, train_neg_s = np.mean(train_neg), np.std(train_neg)\n",
    "        \n",
    "        val_pred = self.model.predict([val_pairs[:, 0], val_pairs[:, 1]])  \n",
    "        val_true = val_labels.astype(int)\n",
    "        val_pos = val_pred[val_true.astype(np.bool)]\n",
    "        val_neg = val_pred[(1 - val_true).astype(np.bool)]\n",
    "        val_pos_m, val_pos_s = np.mean(val_pos), np.std(val_pos)\n",
    "        val_neg_m, val_neg_s = np.mean(val_neg), np.std(val_neg)\n",
    "        \n",
    "        # Precision and recall\n",
    "        threshold = ((val_pos_m + val_pos_s) + (val_neg_m - val_neg_s)) / 2\n",
    "        val_pred = (val_pred.squeeze() < threshold).astype(int)\n",
    "        valid_precision, valid_recall, _, _ = precision_recall_fscore_support(val_true, val_pred, labels=[0, 1])\n",
    "        \n",
    "        train_loss = logs['loss']\n",
    "        valid_loss = logs['val_loss']\n",
    "        logs = {}\n",
    "        logs['train/loss'] = train_loss\n",
    "        \n",
    "        for k, v in class_encoded.items():\n",
    "            logs['train/dist_mean/' + v] = train_pos_m if k else train_neg_m\n",
    "            logs['train/dist_std/' + v] = train_pos_s if k else train_neg_s\n",
    "        \n",
    "        self.tb_writer(logs, wtype='train')\n",
    "        \n",
    "        logs = {}\n",
    "        logs['valid/loss'] = valid_loss\n",
    "        \n",
    "        for k, v in class_encoded.items():\n",
    "            logs['valid/precision/' + v] = valid_precision[k]\n",
    "            logs['valid/recall/' + v] = valid_recall[k]\n",
    "            logs['valid/dist_mean/' + v] = train_pos_m if k else train_neg_m\n",
    "            logs['valid/dist_std/' + v] = train_pos_s if k else train_neg_s\n",
    "\n",
    "        self.tb_writer(logs, wtype='valid')\n",
    "        self.step_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'model_2'\n",
    "\n",
    "#Save training configuration\n",
    "with open(f'configs/{model_name}.json', 'w') as f:\n",
    "    json.dump(train_config, f)\n",
    "\n",
    "logdir = os.path.join('logs', model_name)\n",
    "ckpt_dir = os.path.join('checkpoints', model_name)\n",
    "os.makedirs(ckpt_dir)\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "ckpt_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=os.path.join(ckpt_dir, 'weights.{epoch:02d}-{val_loss:.2f}.hdf5'),\n",
    "    save_weights_only=True,\n",
    "    period=10\n",
    ")\n",
    "metric_callback = MetricCallback(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "20596/20596 [==============================] - 321s 16ms/step - loss: 0.2918 - val_loss: 0.2617\n",
      "Epoch 2/2000\n",
      "20596/20596 [==============================] - 319s 15ms/step - loss: 0.2370 - val_loss: 0.2381\n",
      "Epoch 3/2000\n",
      " 9720/20596 [=============>................] - ETA: 2:28 - loss: 0.2181"
     ]
    }
   ],
   "source": [
    "model.fit([train_pairs[:, 0],\n",
    "           train_pairs[:, 1]],\n",
    "           train_labels,\n",
    "           batch_size=batch_size,\n",
    "           epochs=epochs,\n",
    "           validation_data=([val_pairs[:, 0], val_pairs[:, 1]], val_labels),\n",
    "           callbacks=[metric_callback, ckpt_callback, lr_callback]\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load submission pairs\n",
    "submission_path = 'data/sample_submission.csv'\n",
    "submission_df = pd.read_csv(submission_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models\n",
    "ckpt_path = 'checkpoints/model_1/weights.200-0.12.hdf5'\n",
    "model.load_weights(ckpt_path)\n",
    "embedder = FaceNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over submission pairs\n",
    "is_related = submission_df['is_related']\n",
    "for idx, row in submission_df.iterrows():\n",
    "    # Load images\n",
    "    img_pair = row['img_pair']\n",
    "    img1_name, img2_name = img_pair.split('-')\n",
    "    img1_path = os.path.join('data/test', img1_name)\n",
    "    img2_path = os.path.join('data/test', img2_name)\n",
    "    img1 = image.load_img(img1_path)\n",
    "    img2 = image.load_img(img2_path)\n",
    "    img1 = np.array(img1).astype('float32')\n",
    "    img2 = np.array(img2).astype('float32')\n",
    "    \n",
    "    # Get FaceNet embeddings\n",
    "    embedding1 = embedder.embeddings([img1])\n",
    "    embedding2 = embedder.embeddings([img2])\n",
    "    \n",
    "    # Do an inference, if distance is smaller than margin=1.0 (from contrastive loss)\n",
    "    # then there is the relation\n",
    "    y_pred = model.predict([embedding1, embedding2])\n",
    "    if y_pred.squeeze() < (MARGIN / 1.5):\n",
    "        is_related[idx] = 1\n",
    "    \n",
    "    # Print step\n",
    "    if idx % 100 == 0:\n",
    "        print(f'Processed rows: {idx}')\n",
    "submission_df.to_csv(f'submission_{model_name}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv(f'submission_model_1.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
